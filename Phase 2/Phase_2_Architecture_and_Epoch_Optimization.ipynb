{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Phase 2: Architecture and Epoch Optimization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5PNemoygICJ"
      },
      "source": [
        "#Phase 2: Modeling & Hyperparameter Tuning "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_1wVH_KPCpd"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt #graphs \n",
        "import tensorflow as tf "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgvwUgWeo5z9"
      },
      "source": [
        "**Train, Test, Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DKUEBLPQXO4"
      },
      "source": [
        "#Split validation set by 20%\n",
        "#Image generator helps creating image aumentation to increase the amount of data we have\n",
        "#Will implement various rotations and flips to the images to distort\n",
        "train_gen = ImageDataGenerator(rescale = 1./255, validation_split=0.20)\n",
        "test_gen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "\n",
        "def get_train_set(train_gen, input_size):\n",
        "  train_set = train_gen.flow_from_directory(\"/content/drive/MyDrive/DS 2 dataset/train\",\n",
        "                                         class_mode='categorical',\n",
        "                                         target_size= input_size,\n",
        "                                         color_mode = 'grayscale',\n",
        "                                         batch_size= 32, \n",
        "                                         shuffle = True, \n",
        "                                         subset ='training')\n",
        "  return train_set\n",
        "\n",
        "def get_validation_set(train_gen, input_size):\n",
        "  validation_set = train_gen.flow_from_directory(\"/content/drive/MyDrive/DS 2 dataset/train\",\n",
        "                                          target_size= input_size,\n",
        "                                          color_mode = 'grayscale',\n",
        "                                          class_mode='categorical',\n",
        "                                          batch_size= 32, \n",
        "                                          shuffle = True, \n",
        "                                          subset ='validation')\n",
        "  return validation_set\n",
        "\n",
        "def get_test_set(test_gen, input_size):\n",
        "  test_set = test_gen.flow_from_directory(\"/content/drive/MyDrive/DS 2 dataset/test\",\n",
        "                                         target_size=input_size, \n",
        "                                         color_mode = 'grayscale',\n",
        "                                         class_mode='categorical',\n",
        "                                         batch_size= 1,\n",
        "                                         shuffle = True)\n",
        "  return test_set"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zF_AiurV9XY",
        "outputId": "be7ea632-baea-4b5f-99b2-afc56b4c3cf1"
      },
      "source": [
        "#get train, val, test sets \n",
        "train_set = get_train_set(train_gen=train_gen, input_size = (224,224))\n",
        "val_set = get_validation_set(train_gen=train_gen, input_size = (224,224))\n",
        "test_set = get_test_set(test_gen=test_gen, input_size = (224,224))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6755 images belonging to 196 classes.\n",
            "Found 1585 images belonging to 196 classes.\n",
            "Found 8041 images belonging to 196 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYQyxqAFo0cx"
      },
      "source": [
        "#Modeling & Structural Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne4oTBQblZKQ"
      },
      "source": [
        "!pip install -q -U keras-tuner"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m77SM3xwKLiC",
        "outputId": "32fd5baa-249e-4508-9651-ee2ec461dbf4"
      },
      "source": [
        "from tensorflow.keras.applications import xception #most parameters (44 mil)\n",
        "import keras_tuner as kt\n",
        "from kerastuner.tuners import Hyperband\n",
        "from kerastuner import HyperModel"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjyyLHzOQAUx"
      },
      "source": [
        "#input, conv2d, pooling,flatten ,Dense, output\n",
        "#flatten layer = get vector to put in classifier \n",
        "# conv layers followed by max pool\n",
        "# last conv layer followed by a dropout layer to prevent overfitting \n",
        "# flatten, fully connected layers \n",
        "\n",
        "#TODO: make the number of conv2d layers dynamic\n",
        "\n",
        "class Hypermodel(HyperModel):\n",
        "\n",
        "  def __init__(self, num_Conv2D):\n",
        "    self.num_Conv2D = num_Conv2D\n",
        "\n",
        "  def build(self, hp):\n",
        "    if (self.num_Conv2D <= 0):\n",
        "      return -1\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    \n",
        "    if (self.num_Conv2D == 1):\n",
        "      model.add(tf.keras.layers.Conv2D(filters = hp.Choice('num_filters', values = [32,64], default = 64), kernel_size=(3,3),activation = 'relu',input_shape = (224,224,1)))\n",
        "      model.add(tf.keras.layers.Dropout(hp.Float('dropout',\n",
        "                                                  min_value=0.0,\n",
        "                                                  max_value=0.1,\n",
        "                                                  default=0.005,\n",
        "                                                  step=0.01)))\n",
        "      model.add(tf.keras.layers.MaxPool2D(3,3))\n",
        "    else: \n",
        "      temp = self.num_Conv2D\n",
        "      while (temp-2 > 0):\n",
        "        model.add(tf.keras.layers.Conv2D(filters = hp.Choice('num_filters', values  = [32,64], default = 64), kernel_size=(3,3),activation='relu'))\n",
        "        model.add(tf.keras.layers.MaxPool2D(3,3))\n",
        "        temp = temp -1\n",
        "\n",
        "      model.add(tf.keras.layers.Conv2D(filters = hp.Choice('num_filters', values  = [32,64], default = 64), kernel_size=(3,3),activation='relu'))\n",
        "      model.add(tf.keras.layers.Dropout(hp.Float('dropout',min_value=0.0,max_value=0.1,default=0.005,step=0.01)))\n",
        "      model.add(tf.keras.layers.MaxPool2D(3,3))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(units=hp.Int('units', min_value = 32, max_value=512,step=32),activation= 'relu'))\n",
        "    tf.keras.layers.Dense(196, activation='softmax')\n",
        "    model.compile(optimizer= tf.keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-3])),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "    return model "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIPh_cxsQ2Y_"
      },
      "source": [
        "#don't explore unlikely options \n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8)\n",
        "hypermodel_1 = Hypermodel(num_Conv2D=1)\n",
        "hypermodel_2 = Hypermodel(num_Conv2D=2)\n",
        "hypermodel_3 = Hypermodel(num_Conv2D=3)\n",
        "\n",
        "\n",
        "tuner_1 = Hyperband(hypermodel=hypermodel_1, objective='val_accuracy', max_epochs= 100)\n",
        "tuner_2 = Hyperband(hypermodel=hypermodel_2, objective='val_accuracy', max_epochs= 100)\n",
        "tuner_3 = Hyperband(hypermodel =hypermodel_3, objective = 'val_accuracy', max_epochs = 100)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgrDwNRhiY2u"
      },
      "source": [
        "## 1 Convolutional Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhD-vwo4iF56",
        "outputId": "cbda7358-a08b-4252-d019-1e1900620909"
      },
      "source": [
        "tuner_1.search_space_summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Search space summary\n",
            "Default search space size: 4\n",
            "num_filters (Choice)\n",
            "{'default': 64, 'conditions': [], 'values': [32, 64], 'ordered': True}\n",
            "dropout (Float)\n",
            "{'default': 0.005, 'conditions': [], 'min_value': 0.0, 'max_value': 0.1, 'step': 0.01, 'sampling': None}\n",
            "units (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.001, 'conditions': [], 'values': [0.001], 'ordered': True}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYDg6gvvjIqR",
        "outputId": "66cfed4f-ba65-4299-9b51-62f618db8626"
      },
      "source": [
        "tuner_1.search(train_set, epochs = 50, validation_data = val_set, callbacks = [stop_early])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Search: Running Trial #1\n",
            "\n",
            "Hyperparameter    |Value             |Best Value So Far \n",
            "num_filters       |64                |?                 \n",
            "dropout           |0.03              |?                 \n",
            "units             |448               |?                 \n",
            "learning_rate     |0.001             |?                 \n",
            "tuner/epochs      |2                 |?                 \n",
            "tuner/initial_e...|0                 |?                 \n",
            "tuner/bracket     |4                 |?                 \n",
            "tuner/round       |0                 |?                 \n",
            "\n",
            "Epoch 1/2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCkGSGmTilRl"
      },
      "source": [
        "## 2 Convolutional Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8aJdggxiO-J"
      },
      "source": [
        "tuner_2.search_space_summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDwkGff9jIz0"
      },
      "source": [
        "tuner_2.search(train_set, epochs = 50, validation_data = val_set, callbacks = [stop_early])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YQhQrMdiq7h"
      },
      "source": [
        "## 3 Convolutional Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UeQMTJIiQsN"
      },
      "source": [
        "tuner_3.search_space_summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nij6mzQ1jM1I"
      },
      "source": [
        "tuner_3.search(train_set, epochs = 50, validation_data = val_set, callbacks = [stop_early])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7vkk1yPJCq_"
      },
      "source": [
        "**Epoch Optimization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mhWpZHXXCHZ"
      },
      "source": [
        "# get best hp\n",
        "best_hps = tuner_1.get_best_hyperparameters(num_trials = 1)[0]\n",
        "#build best model \n",
        "model = tuner_1.hypermodel.build(best_hps)\n",
        "hist = model.fit(train_set,epochs = 100, validation_data = val_set)\n",
        "\n",
        "#get best epoch \n",
        "val_acc_per_epoch = hist.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch))+ 1\n",
        "\n",
        "print('Best Epoch: %d' % (best_epoch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uhap6vNXDm-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT6DN-u4UbrQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aa9fQrvVOuh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo68UhQkXC77"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}