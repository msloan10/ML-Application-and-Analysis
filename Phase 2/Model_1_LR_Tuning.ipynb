{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Phase 2 Modeling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5PNemoygICJ"
      },
      "source": [
        "#Phase 2: Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_1wVH_KPCpd"
      },
      "source": [
        "#from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt #graphs \n",
        "import tensorflow as tf \n",
        "#import sklearn as skl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgvwUgWeo5z9"
      },
      "source": [
        "**Train, Test, Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DKUEBLPQXO4"
      },
      "source": [
        "#Split validation set by 20%\n",
        "#Image generator helps creating image aumentation to increase the amount of data we have\n",
        "#Will implement various rotations and flips to the images to distort\n",
        "train_gen = ImageDataGenerator(rescale = 1./255, validation_split=0.20)\n",
        "test_gen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "\n",
        "def get_train_set(train_gen, input_size):\n",
        "  train_set = train_gen.flow_from_directory(\"/content/drive/MyDrive/DS 2 dataset/train\",\n",
        "                                         class_mode='categorical',\n",
        "                                         target_size= input_size,\n",
        "                                         color_mode = 'grayscale',\n",
        "                                         batch_size= 32, \n",
        "                                         shuffle = True, \n",
        "                                         subset ='training')\n",
        "  return train_set\n",
        "\n",
        "def get_validation_set(train_gen, input_size):\n",
        "  validation_set = train_gen.flow_from_directory(\"/content/drive/MyDrive/DS 2 dataset/train\",\n",
        "                                          target_size= input_size,\n",
        "                                          color_mode = 'grayscale',\n",
        "                                          class_mode='categorical',\n",
        "                                          batch_size= 32, \n",
        "                                          shuffle = True, \n",
        "                                          subset ='validation')\n",
        "  return validation_set\n",
        "\n",
        "def get_test_set(test_gen, input_size):\n",
        "  test_set = test_gen.flow_from_directory(\"/content/drive/MyDrive/DS 2 dataset/test\",\n",
        "                                         target_size=input_size, \n",
        "                                         color_mode = 'grayscale',\n",
        "                                         class_mode='categorical',\n",
        "                                         batch_size= 1,\n",
        "                                         shuffle = True)\n",
        "  return test_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYQyxqAFo0cx"
      },
      "source": [
        "#Modeling & Hyper-parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne4oTBQblZKQ",
        "outputId": "001e8b0d-3aa5-41cd-e2c4-5c2fac6a7c77"
      },
      "source": [
        "!pip install -q -U keras-tuner"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |███▍                            | 10 kB 36.3 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 20 kB 39.2 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 30 kB 21.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 40 kB 18.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 51 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 61 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 71 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 81 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 92 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 96 kB 4.7 MB/s \n",
            "\u001b[?25h  Building wheel for kt-legacy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m77SM3xwKLiC",
        "outputId": "4ad4e13f-ac12-4ef4-a105-7ec88bf78ff6"
      },
      "source": [
        "from tensorflow.keras.applications import xception #most parameters (44 mil)\n",
        "import keras_tuner as kt\n",
        "from kerastuner.tuners import RandomSearch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjyyLHzOQAUx"
      },
      "source": [
        "  #input, conv2d, pooling,flatten ,Dense, output\n",
        "  #Sequential = order layers are vistied\n",
        "  #flatten layer = get vector to put in classifier \n",
        "\n",
        "  # 3 conv layers followed by max pool \n",
        "  # 3rd conv layer followed by a dropout layer to prevent overfitting \n",
        "  # flatten, fully connected layers \n",
        "\n",
        "def build_scratch_model(hp):\n",
        "    model = tf.keras.Sequential([tf.keras.layers.Conv2D(filters = hp.Choice('num_filters', \n",
        "                                                                          values = [32,64], \n",
        "                                                                          default = 64), kernel_size=(3,3),\n",
        "                                                      activation = 'relu',input_shape = (224,224,1)),\n",
        "                               \n",
        "                               tf.keras.layers.MaxPool2D(3,3),\n",
        "\n",
        "                               tf.keras.layers.Conv2D(filters = hp.Choice('num_filters', values  = [32,64], default = 64), kernel_size=(3,3),activation='relu'),\n",
        "                               tf.keras.layers.MaxPool2D(3,3),\n",
        "\n",
        "                               tf.keras.layers.Conv2D(filters = hp.Choice('num_filters',\n",
        "                                                                          values  = [32,64],\n",
        "                                                                          default = 64), kernel_size=(3,3),\n",
        "                                                      activation='relu'),\n",
        "\n",
        "                               tf.keras.layers.Dropout(hp.Float('dropout',\n",
        "                                                                min_value=0.0,\n",
        "                                                                max_value=0.1,\n",
        "                                                                default=0.005,\n",
        "                                                                step=0.01)),\n",
        "                               tf.keras.layers.MaxPool2D(3,3),\n",
        "\n",
        "                               tf.keras.layers.Flatten(),\n",
        "\n",
        "                               tf.keras.layers.Dense(units=hp.Int('units', min_value = 32,\n",
        "                                                                  max_value=512,\n",
        "                                                                  step=32),\n",
        "                                                     activation= 'relu'),\n",
        "                               \n",
        "                               tf.keras.layers.Dense(196, activation='softmax')])\n",
        "  \n",
        "    model.compile(optimizer= tf.keras.optimizers.Adam(hp.Choice('learning_rate',\n",
        "                      values=[1e-2, 1e-3, 1e-4])),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "    \n",
        "  \n",
        "    return model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIPh_cxsQ2Y_"
      },
      "source": [
        "tuner_1 = RandomSearch(hypermodel=build_scratch_model, objective='val_accuracy', max_trials= 10, seed = 25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhD-vwo4iF56",
        "outputId": "caf780e0-f09b-4376-f766-9dea8a0f816e"
      },
      "source": [
        "tuner_1.search_space_summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Search space summary\n",
            "Default search space size: 4\n",
            "num_filters (Choice)\n",
            "{'default': 64, 'conditions': [], 'values': [32, 64], 'ordered': True}\n",
            "dropout (Float)\n",
            "{'default': 0.005, 'conditions': [], 'min_value': 0.0, 'max_value': 0.1, 'step': 0.01, 'sampling': None}\n",
            "units (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYDg6gvvjIqR",
        "outputId": "9b650954-e0ee-442d-9ba5-fa49a7acdaf1"
      },
      "source": [
        "tuner_1.search(get_train_set(train_gen=train_gen, input_size = (224,224)), epochs = 50, validation_data = get_validation_set(train_gen=train_gen, input_size= (224,224)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 10 Complete [00h 14m 17s]\n",
            "val_accuracy: 0.07697160542011261\n",
            "\n",
            "Best val_accuracy So Far: 0.13123027980327606\n",
            "Total elapsed time: 03h 02m 23s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNkpRAfPTVr0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f6f0a22-8577-4591-d74d-a9404277f9f9"
      },
      "source": [
        " tuner_1.results_summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in ./untitled_project\n",
            "Showing 10 best trials\n",
            "Objective(name='val_accuracy', direction='max')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_filters: 64\n",
            "dropout: 0.09\n",
            "units: 256\n",
            "learning_rate: 0.001\n",
            "Score: 0.13123027980327606\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_filters: 32\n",
            "dropout: 0.05\n",
            "units: 288\n",
            "learning_rate: 0.001\n",
            "Score: 0.11798107624053955\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_filters: 64\n",
            "dropout: 0.06\n",
            "units: 64\n",
            "learning_rate: 0.001\n",
            "Score: 0.1022082045674324\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_filters: 32\n",
            "dropout: 0.05\n",
            "units: 160\n",
            "learning_rate: 0.001\n",
            "Score: 0.10094637423753738\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_filters: 32\n",
            "dropout: 0.06\n",
            "units: 128\n",
            "learning_rate: 0.001\n",
            "Score: 0.09968454390764236\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_filters: 64\n",
            "dropout: 0.09\n",
            "units: 192\n",
            "learning_rate: 0.0001\n",
            "Score: 0.09716088324785233\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_filters: 64\n",
            "dropout: 0.01\n",
            "units: 64\n",
            "learning_rate: 0.0001\n",
            "Score: 0.07697160542011261\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_filters: 32\n",
            "dropout: 0.09\n",
            "units: 64\n",
            "learning_rate: 0.0001\n",
            "Score: 0.07192429155111313\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_filters: 64\n",
            "dropout: 0.07\n",
            "units: 352\n",
            "learning_rate: 0.01\n",
            "Score: 0.010725552216172218\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_filters: 32\n",
            "dropout: 0.05\n",
            "units: 32\n",
            "learning_rate: 0.01\n",
            "Score: 0.010725552216172218\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-fcjjYM6nmk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "496ba4df-f8ab-4b83-ff06-fa640b305872"
      },
      "source": [
        "best_model = tuner_1.get_best_models(num_models=1)[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6fMUMrka4s6"
      },
      "source": [
        "**Conclusion:** The models with a learning rate of 0.001 had the best validation scores. "
      ]
    }
  ]
}