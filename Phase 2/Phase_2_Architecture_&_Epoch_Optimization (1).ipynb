{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Phase 2: Architecture & Epoch Optimization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5PNemoygICJ"
      },
      "source": [
        "#Phase 2: Modeling & Hyperparameter Tuning "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne4oTBQblZKQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44ba7734-c3bf-443e-f44b-41a20e04ff6d"
      },
      "source": [
        "!pip install -q -U keras-tuner"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |███▍                            | 10 kB 16.9 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 20 kB 21.7 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 30 kB 26.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 40 kB 27.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 51 kB 21.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 61 kB 22.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 71 kB 22.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 81 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 92 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 96 kB 3.7 MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_1wVH_KPCpd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b8265fb-dadb-4f71-81c1-13ff4a1f79da"
      },
      "source": [
        "%matplotlib inline \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from kerastuner.tuners import Hyperband\n",
        "from kerastuner import HyperModel\n",
        "import matplotlib.pyplot as plt #graphs \n",
        "import tensorflow as tf \n",
        "import keras_tuner as kt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgvwUgWeo5z9"
      },
      "source": [
        "**Data Augmentation & Test, Train, Validation Split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DKUEBLPQXO4"
      },
      "source": [
        "#Split validation set by 20%\n",
        "#Image generator helps creating image aumentation to increase the amount of data we have\n",
        "#Will implement various rotations and flips to the images to distort\n",
        "train_gen = ImageDataGenerator(rescale = 1./255, \n",
        "                               validation_split=0.20, \n",
        "                               rotation_range=45, \n",
        "                               width_shift_range=0.2, \n",
        "                               height_shift_range=0.2, \n",
        "                               horizontal_flip=True)\n",
        "\n",
        "test_gen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "\n",
        "def get_train_set(train_gen, input_size):\n",
        "  train_set = train_gen.flow_from_directory(\"/content/drive/MyDrive/DS 2 dataset/train\",\n",
        "                                         class_mode='categorical',\n",
        "                                         target_size= input_size,\n",
        "                                         color_mode = 'grayscale',\n",
        "                                         batch_size= 32, \n",
        "                                         shuffle = True, \n",
        "                                         subset ='training')\n",
        "  return train_set\n",
        "\n",
        "def get_validation_set(train_gen, input_size):\n",
        "  validation_set = train_gen.flow_from_directory(\"/content/drive/MyDrive/DS 2 dataset/train\",\n",
        "                                          target_size= input_size,\n",
        "                                          color_mode = 'grayscale',\n",
        "                                          class_mode='categorical',\n",
        "                                          batch_size= 32, \n",
        "                                          shuffle = True, \n",
        "                                          subset ='validation')\n",
        "  return validation_set\n",
        "\n",
        "def get_test_set(test_gen, input_size):\n",
        "  test_set = test_gen.flow_from_directory(\"/content/drive/MyDrive/DS 2 dataset/test\",\n",
        "                                         target_size=input_size, \n",
        "                                         color_mode = 'grayscale',\n",
        "                                         class_mode='categorical',\n",
        "                                         batch_size= 1,\n",
        "                                         shuffle = True)\n",
        "  return test_set"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zF_AiurV9XY",
        "outputId": "0150d701-6eb0-46e6-c799-fac3b2fbf295"
      },
      "source": [
        "#get train, val, test sets \n",
        "train_set = get_train_set(train_gen=train_gen, input_size = (224,224))\n",
        "val_set = get_validation_set(train_gen=train_gen, input_size = (224,224))\n",
        "test_set = get_test_set(test_gen=test_gen, input_size = (224,224))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6755 images belonging to 196 classes.\n",
            "Found 1585 images belonging to 196 classes.\n",
            "Found 8041 images belonging to 196 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYQyxqAFo0cx"
      },
      "source": [
        "##Structural Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfYUSzBym5HA",
        "outputId": "a6743967-cec0-41e3-bca8-f6e3fc9a73cf"
      },
      "source": [
        "input_shape = (224,224,1)\n",
        "model = tf.keras.applications.InceptionV3(include_top = False, weights= None,input_shape=input_shape)\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 224, 224, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 111, 111, 32) 288         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 111, 111, 32) 96          conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 111, 111, 32) 0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 109, 109, 32) 9216        activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 109, 109, 32) 96          conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 109, 109, 32) 0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 109, 109, 64) 18432       activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 109, 109, 64) 192         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 109, 109, 64) 0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 54, 54, 80)   5120        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 54, 54, 80)   240         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 54, 54, 80)   0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 52, 52, 192)  138240      activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 52, 52, 192)  576         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 52, 52, 192)  0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 25, 25, 64)   192         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 25, 25, 64)   0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 25, 25, 48)   9216        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 25, 25, 96)   55296       activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 25, 25, 48)   144         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 25, 25, 96)   288         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 25, 25, 48)   0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 25, 25, 96)   0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 25, 25, 192)  0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 25, 25, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 25, 25, 64)   76800       activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 25, 25, 96)   82944       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 25, 25, 32)   6144        average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 25, 25, 64)   192         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 25, 25, 64)   192         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 25, 25, 96)   288         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 25, 25, 32)   96          conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 25, 25, 64)   0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 25, 25, 64)   0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 25, 25, 96)   0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 25, 25, 32)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_99[0][0]              \n",
            "                                                                 activation_101[0][0]             \n",
            "                                                                 activation_104[0][0]             \n",
            "                                                                 activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 25, 25, 64)   192         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 25, 25, 64)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 25, 25, 96)   55296       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 25, 25, 48)   144         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 25, 25, 96)   288         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 25, 25, 48)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 25, 25, 96)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 25, 25, 64)   76800       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 25, 25, 96)   82944       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 25, 25, 64)   16384       average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 25, 25, 64)   192         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 25, 25, 64)   192         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 25, 25, 96)   288         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 25, 25, 64)   192         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 25, 25, 64)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 25, 25, 64)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 25, 25, 96)   0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 25, 25, 64)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_106[0][0]             \n",
            "                                                                 activation_108[0][0]             \n",
            "                                                                 activation_111[0][0]             \n",
            "                                                                 activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 25, 25, 64)   192         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 25, 25, 64)   0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 25, 25, 96)   55296       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 25, 25, 48)   144         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 25, 25, 96)   288         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 25, 25, 48)   0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 25, 25, 96)   0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 25, 25, 64)   76800       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 25, 25, 96)   82944       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 25, 25, 64)   18432       average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 25, 25, 64)   192         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 25, 25, 64)   192         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 25, 25, 96)   288         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 25, 25, 64)   192         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 25, 25, 64)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 25, 25, 64)   0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 25, 25, 96)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 25, 25, 64)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_113[0][0]             \n",
            "                                                                 activation_115[0][0]             \n",
            "                                                                 activation_118[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 25, 25, 64)   192         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 25, 25, 64)   0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 25, 25, 96)   55296       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 25, 25, 96)   288         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 25, 25, 96)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 12, 12, 96)   82944       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 12, 12, 384)  1152        conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 12, 12, 96)   288         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 12, 12, 384)  0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 12, 12, 96)   0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_120[0][0]             \n",
            "                                                                 activation_123[0][0]             \n",
            "                                                                 max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 12, 12, 128)  384         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 12, 12, 128)  0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 12, 12, 128)  114688      activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 12, 12, 128)  384         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 12, 12, 128)  0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 12, 12, 128)  114688      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 12, 12, 128)  384         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 12, 12, 128)  384         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 12, 12, 128)  0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 12, 12, 128)  0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 12, 12, 128)  114688      activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 12, 12, 128)  114688      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 12, 12, 128)  384         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 12, 12, 128)  384         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 12, 12, 128)  0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 12, 12, 128)  0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 12, 12, 192)  172032      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 12, 12, 192)  172032      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 12, 12, 192)  576         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 12, 12, 192)  576         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 12, 12, 192)  576         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 12, 12, 192)  576         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 12, 12, 192)  0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 12, 12, 192)  0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 12, 12, 192)  0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 12, 12, 192)  0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_124[0][0]             \n",
            "                                                                 activation_127[0][0]             \n",
            "                                                                 activation_132[0][0]             \n",
            "                                                                 activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 12, 12, 160)  480         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 12, 12, 160)  0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 12, 12, 160)  179200      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 12, 12, 160)  480         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 12, 12, 160)  0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 12, 12, 160)  179200      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 12, 12, 160)  480         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 12, 12, 160)  480         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 12, 12, 160)  0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 12, 12, 160)  0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 12, 12, 160)  179200      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 12, 12, 160)  179200      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 12, 12, 160)  480         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 12, 12, 160)  480         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 12, 12, 160)  0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 12, 12, 160)  0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 12, 12, 192)  215040      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 12, 12, 192)  215040      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 12, 12, 192)  576         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 12, 12, 192)  576         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 12, 12, 192)  576         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 12, 12, 192)  576         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 12, 12, 192)  0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 12, 12, 192)  0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 12, 12, 192)  0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 12, 12, 192)  0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_134[0][0]             \n",
            "                                                                 activation_137[0][0]             \n",
            "                                                                 activation_142[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 12, 12, 160)  480         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 12, 12, 160)  0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 12, 12, 160)  179200      activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 12, 12, 160)  480         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 12, 12, 160)  0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 12, 12, 160)  179200      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 12, 12, 160)  480         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 12, 12, 160)  480         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 12, 12, 160)  0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 12, 12, 160)  0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 12, 12, 160)  179200      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 12, 12, 160)  179200      activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 12, 12, 160)  480         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 12, 12, 160)  480         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 12, 12, 160)  0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 12, 12, 160)  0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 12, 12, 192)  215040      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 12, 12, 192)  215040      activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 12, 12, 192)  576         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 12, 12, 192)  576         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 12, 12, 192)  576         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 12, 12, 192)  576         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 12, 12, 192)  0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 12, 12, 192)  0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 12, 12, 192)  0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 12, 12, 192)  0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_144[0][0]             \n",
            "                                                                 activation_147[0][0]             \n",
            "                                                                 activation_152[0][0]             \n",
            "                                                                 activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 12, 12, 192)  576         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 12, 12, 192)  0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 12, 12, 192)  258048      activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 12, 12, 192)  576         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 12, 12, 192)  0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 12, 12, 192)  258048      activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 12, 12, 192)  576         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 12, 12, 192)  576         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 12, 12, 192)  0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 12, 12, 192)  0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 12, 12, 192)  258048      activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 12, 12, 192)  258048      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 12, 12, 192)  576         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 12, 12, 192)  576         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 12, 12, 192)  0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 12, 12, 192)  0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 12, 12, 192)  258048      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 12, 12, 192)  258048      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 12, 12, 192)  576         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 12, 12, 192)  576         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 12, 12, 192)  576         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 12, 12, 192)  576         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 12, 12, 192)  0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 12, 12, 192)  0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 12, 12, 192)  0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 12, 12, 192)  0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_154[0][0]             \n",
            "                                                                 activation_157[0][0]             \n",
            "                                                                 activation_162[0][0]             \n",
            "                                                                 activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 12, 12, 192)  576         conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 12, 12, 192)  0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 12, 12, 192)  258048      activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 12, 12, 192)  576         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 12, 12, 192)  0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 12, 12, 192)  258048      activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 12, 12, 192)  576         conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 12, 12, 192)  576         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 12, 12, 192)  0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 12, 12, 192)  0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 5, 5, 320)    552960      activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 5, 5, 192)    331776      activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 5, 5, 320)    960         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 5, 5, 192)    576         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 5, 5, 320)    0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 5, 5, 192)    0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_165[0][0]             \n",
            "                                                                 activation_169[0][0]             \n",
            "                                                                 max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 5, 5, 448)    1344        conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 5, 5, 448)    0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 5, 5, 384)    1548288     activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 5, 5, 384)    1152        conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 5, 5, 384)    1152        conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 5, 5, 384)    0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 5, 5, 384)    0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 5, 5, 384)    442368      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 5, 5, 384)    442368      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 5, 5, 384)    442368      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 5, 5, 384)    442368      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_16 (AveragePo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 5, 5, 384)    1152        conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 5, 5, 384)    1152        conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 5, 5, 384)    1152        conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 5, 5, 384)    1152        conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 5, 5, 192)    245760      average_pooling2d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 5, 5, 320)    960         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 5, 5, 384)    0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 5, 5, 384)    0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 5, 5, 384)    0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 5, 5, 384)    0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 5, 5, 192)    576         conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 5, 5, 320)    0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_172[0][0]             \n",
            "                                                                 activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 5, 5, 768)    0           activation_176[0][0]             \n",
            "                                                                 activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 5, 5, 192)    0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_170[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 5, 5, 448)    1344        conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 5, 5, 448)    0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 5, 5, 384)    1548288     activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 5, 5, 384)    1152        conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 5, 5, 384)    1152        conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 5, 5, 384)    0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 5, 5, 384)    0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 5, 5, 384)    442368      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 5, 5, 384)    442368      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 5, 5, 384)    442368      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 5, 5, 384)    442368      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_17 (AveragePo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 5, 5, 384)    1152        conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 5, 5, 384)    1152        conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 5, 5, 384)    1152        conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 5, 5, 384)    1152        conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 5, 5, 192)    393216      average_pooling2d_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 5, 5, 320)    960         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 5, 5, 384)    0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 5, 5, 384)    0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 5, 5, 384)    0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 5, 5, 384)    0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 5, 5, 192)    576         conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 5, 5, 320)    0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_181[0][0]             \n",
            "                                                                 activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 5, 5, 768)    0           activation_185[0][0]             \n",
            "                                                                 activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 5, 5, 192)    0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_179[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_3[0][0]              \n",
            "                                                                 activation_187[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 21,802,208\n",
            "Trainable params: 21,767,776\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjyyLHzOQAUx"
      },
      "source": [
        "#input, conv2d, pooling, flatten, Dense, output\n",
        "#flatten layer = get vector to put in classifier \n",
        "# conv layers followed by max pool\n",
        "# last conv layer followed by a dropout layer to prevent overfitting \n",
        "# flatten, fully connected layers \n",
        "\n",
        "class Hypermodel(HyperModel):\n",
        "\n",
        "  def __init__(self, NN_Type):\n",
        "    self.NN_Type = NN_Type\n",
        "\n",
        "  def build(self, hp):\n",
        "    if (self.NN_Type != 'GoogleNet' and self.NN_Type != 'VGG16' and self.NN_Type != 'ResNet152'):\n",
        "      raise ValueError(\"Invalid model type\")\n",
        "    if (self.NN_Type == 'GoogleNet'):\n",
        "      model = tf.keras.applications.InceptionV3(include_top = False, input_shape=(224, 224, 1), classes = 196)\n",
        "      #flatten\n",
        "      output_layer = tf.keras.layers('')\n",
        "      x = tf.keras.layers.Flatten()\n",
        "      #dense\n",
        "      #dropout\n",
        "      #classification layer(dense)\n",
        "    elif (self.NN_Type == 'VGG16'):\n",
        "      tf.keras.applications.VGG16()\n",
        "    else: \n",
        "      tf.keras.applications.ResNet152()\n",
        "    return model\n",
        "  \n",
        "  def summary(self):\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIPh_cxsQ2Y_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d31496d9-107b-40ad-dae2-cab6e03a7d70"
      },
      "source": [
        "#don't explore unlikely options \n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8)\n",
        "\n",
        "#create model checkpoint (save at this point)\n",
        "\n",
        "\n",
        "hypermodel_Google = Hypermodel(NN_Type = 'GoogleNet')\n",
        "hypermodel_VGG = Hypermodel(NN_Type = 'VGG16')\n",
        "hypermodel_ResNet = Hypermodel(NN_Type = 'GoogleNet')\n",
        "\n",
        "tuner_GN = Hyperband(hypermodel =hypermodel_Google, objective = 'val_accuracy', max_epochs = 100)\n",
        "tuner_VGG = Hyperband(hypermodel=hypermodel_VGG, objective='val_accuracy', max_epochs=100)\n",
        "tuner_ResNet = Hyperband(hypermodel=hypermodel_ResNet, objective='val_accuracy', max_epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reloading Oracle from existing project ./untitled_project/oracle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YQhQrMdiq7h"
      },
      "source": [
        "**GoogleNet Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UeQMTJIiQsN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57c4a5b8-d41c-4cbc-9d1b-8708afd032b8"
      },
      "source": [
        "tuner_GN.search_space_summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Search space summary\n",
            "Default search space size: 4\n",
            "num_filters (Choice)\n",
            "{'default': 64, 'conditions': [], 'values': [32, 64], 'ordered': True}\n",
            "dropout (Float)\n",
            "{'default': 0.005, 'conditions': [], 'min_value': 0.0, 'max_value': 0.1, 'step': 0.01, 'sampling': None}\n",
            "units (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.001, 'conditions': [], 'values': [0.001], 'ordered': True}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nij6mzQ1jM1I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "674d0c43-c7c7-489a-e984-88397f4cef23"
      },
      "source": [
        "tuner_GN.search(train_set, epochs = 50, validation_data = val_set, callbacks = [stop_early])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 90 Complete [00h 02m 38s]\n",
            "val_accuracy: 0.06813880056142807\n",
            "\n",
            "Best val_accuracy So Far: 0.10599368810653687\n",
            "Total elapsed time: 03h 29m 38s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdXzI04uMJva"
      },
      "source": [
        "**VGG16 Validation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9TZO9jsMaF5"
      },
      "source": [
        "**ResNet152 Validation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7vkk1yPJCq_"
      },
      "source": [
        "##Epoch Optimization for Best Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mhWpZHXXCHZ"
      },
      "source": [
        "# get best hp\n",
        "best_hps = tuner_3.get_best_hyperparameters(num_trials =1)[0]\n",
        "model = tuner_3.hypermodel.build(best_hps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ2XrQ_Van95",
        "outputId": "38df2676-a756-4403-f000-f94fc679e7b2"
      },
      "source": [
        "#num filters, dropout, densely connected layer \n",
        "print(\"Best num_filters: %d\" %(best_hps.get('num_filters')))\n",
        "print(\"Best dropout: %f\" %(best_hps.get('dropout')))\n",
        "print(\"Best number of units: %d\" % (best_hps.get('units')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best num_filters: 32\n",
            "Best dropout: 0.050000\n",
            "Best number of units: 448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uhap6vNXDm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e323931d-9508-4f28-c62c-e4a0b1c84385"
      },
      "source": [
        "hist = model.fit(train_set, epochs = 120, validation_data = val_set)\n",
        "val_acc_per_epoch = hist.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/120\n",
            "212/212 [==============================] - 16s 75ms/step - loss: 5.2710 - accuracy: 0.0067 - val_loss: 5.1722 - val_accuracy: 0.0189\n",
            "Epoch 2/120\n",
            "212/212 [==============================] - 16s 74ms/step - loss: 4.5798 - accuracy: 0.0836 - val_loss: 4.7165 - val_accuracy: 0.0644\n",
            "Epoch 3/120\n",
            "212/212 [==============================] - 17s 79ms/step - loss: 2.4509 - accuracy: 0.4289 - val_loss: 5.4789 - val_accuracy: 0.0751\n",
            "Epoch 4/120\n",
            "212/212 [==============================] - 16s 77ms/step - loss: 0.6114 - accuracy: 0.8623 - val_loss: 6.9725 - val_accuracy: 0.0738\n",
            "Epoch 5/120\n",
            "212/212 [==============================] - 17s 79ms/step - loss: 0.2465 - accuracy: 0.9553 - val_loss: 7.1976 - val_accuracy: 0.0776\n",
            "Epoch 6/120\n",
            "212/212 [==============================] - 16s 77ms/step - loss: 0.1627 - accuracy: 0.9708 - val_loss: 6.8413 - val_accuracy: 0.0858\n",
            "Epoch 7/120\n",
            "212/212 [==============================] - 16s 74ms/step - loss: 0.1175 - accuracy: 0.9726 - val_loss: 6.7241 - val_accuracy: 0.0770\n",
            "Epoch 8/120\n",
            "212/212 [==============================] - 16s 74ms/step - loss: 0.0959 - accuracy: 0.9742 - val_loss: 6.4852 - val_accuracy: 0.0789\n",
            "Epoch 9/120\n",
            "212/212 [==============================] - 17s 79ms/step - loss: 0.0887 - accuracy: 0.9732 - val_loss: 6.5523 - val_accuracy: 0.0814\n",
            "Epoch 10/120\n",
            "212/212 [==============================] - 16s 78ms/step - loss: 0.0837 - accuracy: 0.9725 - val_loss: 6.3535 - val_accuracy: 0.0845\n",
            "Epoch 11/120\n",
            "212/212 [==============================] - 16s 74ms/step - loss: 0.0749 - accuracy: 0.9729 - val_loss: 6.2328 - val_accuracy: 0.0833\n",
            "Epoch 12/120\n",
            "212/212 [==============================] - 16s 76ms/step - loss: 0.0706 - accuracy: 0.9711 - val_loss: 6.3258 - val_accuracy: 0.0782\n",
            "Epoch 13/120\n",
            "212/212 [==============================] - 17s 79ms/step - loss: 0.0649 - accuracy: 0.9742 - val_loss: 6.6003 - val_accuracy: 0.0883\n",
            "Epoch 14/120\n",
            "212/212 [==============================] - 16s 78ms/step - loss: 0.0694 - accuracy: 0.9753 - val_loss: 6.4143 - val_accuracy: 0.0820\n",
            "Epoch 15/120\n",
            "212/212 [==============================] - 16s 74ms/step - loss: 0.0612 - accuracy: 0.9753 - val_loss: 6.4818 - val_accuracy: 0.0814\n",
            "Epoch 16/120\n",
            "212/212 [==============================] - 16s 74ms/step - loss: 0.0621 - accuracy: 0.9735 - val_loss: 6.3788 - val_accuracy: 0.0801\n",
            "Epoch 17/120\n",
            "212/212 [==============================] - 16s 77ms/step - loss: 0.0595 - accuracy: 0.9723 - val_loss: 6.4281 - val_accuracy: 0.0826\n",
            "Epoch 18/120\n",
            "212/212 [==============================] - 17s 78ms/step - loss: 0.0548 - accuracy: 0.9757 - val_loss: 6.6104 - val_accuracy: 0.0751\n",
            "Epoch 19/120\n",
            "212/212 [==============================] - 16s 74ms/step - loss: 0.0591 - accuracy: 0.9731 - val_loss: 6.3326 - val_accuracy: 0.0871\n",
            "Epoch 20/120\n",
            "212/212 [==============================] - 16s 74ms/step - loss: 0.0566 - accuracy: 0.9728 - val_loss: 6.3254 - val_accuracy: 0.0820\n",
            "Epoch 21/120\n",
            "212/212 [==============================] - 16s 75ms/step - loss: 0.0516 - accuracy: 0.9759 - val_loss: 6.5251 - val_accuracy: 0.0814\n",
            "Epoch 22/120\n",
            "212/212 [==============================] - 17s 79ms/step - loss: 0.0510 - accuracy: 0.9734 - val_loss: 6.6025 - val_accuracy: 0.0826\n",
            "Epoch 23/120\n",
            "212/212 [==============================] - 16s 75ms/step - loss: 0.0554 - accuracy: 0.9742 - val_loss: 6.8135 - val_accuracy: 0.0808\n",
            "Epoch 24/120\n",
            "212/212 [==============================] - 16s 74ms/step - loss: 0.0591 - accuracy: 0.9751 - val_loss: 6.7970 - val_accuracy: 0.0801\n",
            "Epoch 25/120\n",
            "212/212 [==============================] - 16s 78ms/step - loss: 0.0544 - accuracy: 0.9744 - val_loss: 6.3893 - val_accuracy: 0.0890\n",
            "Epoch 26/120\n",
            "212/212 [==============================] - 17s 79ms/step - loss: 0.0512 - accuracy: 0.9732 - val_loss: 6.9386 - val_accuracy: 0.0852\n",
            "Epoch 27/120\n",
            "212/212 [==============================] - 17s 78ms/step - loss: 0.0547 - accuracy: 0.9734 - val_loss: 6.6973 - val_accuracy: 0.0770\n",
            "Epoch 28/120\n",
            "212/212 [==============================] - 17s 79ms/step - loss: 0.3740 - accuracy: 0.8974 - val_loss: 8.3389 - val_accuracy: 0.0549\n",
            "Epoch 29/120\n",
            "212/212 [==============================] - 16s 74ms/step - loss: 0.2900 - accuracy: 0.9147 - val_loss: 8.9671 - val_accuracy: 0.0625\n",
            "Epoch 30/120\n",
            "212/212 [==============================] - 16s 75ms/step - loss: 0.0915 - accuracy: 0.9686 - val_loss: 8.3815 - val_accuracy: 0.0669\n",
            "Epoch 31/120\n",
            "212/212 [==============================] - 16s 77ms/step - loss: 0.0522 - accuracy: 0.9739 - val_loss: 7.9286 - val_accuracy: 0.0732\n",
            "Epoch 32/120\n",
            "212/212 [==============================] - 17s 79ms/step - loss: 0.0433 - accuracy: 0.9735 - val_loss: 7.9400 - val_accuracy: 0.0713\n",
            "Epoch 33/120\n",
            "212/212 [==============================] - 16s 74ms/step - loss: 0.0406 - accuracy: 0.9736 - val_loss: 7.9285 - val_accuracy: 0.0738\n",
            "Epoch 34/120\n",
            "212/212 [==============================] - 16s 75ms/step - loss: 0.0403 - accuracy: 0.9741 - val_loss: 7.9703 - val_accuracy: 0.0744\n",
            "Epoch 35/120\n",
            "212/212 [==============================] - 16s 77ms/step - loss: 0.0380 - accuracy: 0.9744 - val_loss: 7.8188 - val_accuracy: 0.0726\n",
            "Epoch 36/120\n",
            "212/212 [==============================] - 17s 80ms/step - loss: 0.0385 - accuracy: 0.9735 - val_loss: 7.8820 - val_accuracy: 0.0763\n",
            "Epoch 37/120\n",
            "212/212 [==============================] - 16s 74ms/step - loss: 0.0377 - accuracy: 0.9751 - val_loss: 7.7735 - val_accuracy: 0.0751\n",
            "Epoch 38/120\n",
            "212/212 [==============================] - 16s 76ms/step - loss: 0.0396 - accuracy: 0.9750 - val_loss: 7.6022 - val_accuracy: 0.0757\n",
            "Epoch 39/120\n",
            "212/212 [==============================] - 16s 77ms/step - loss: 0.0369 - accuracy: 0.9745 - val_loss: 7.6858 - val_accuracy: 0.0770\n",
            "Epoch 40/120\n",
            "212/212 [==============================] - 17s 79ms/step - loss: 0.0368 - accuracy: 0.9741 - val_loss: 7.8973 - val_accuracy: 0.0789\n",
            "Epoch 41/120\n",
            "212/212 [==============================] - 16s 75ms/step - loss: 0.0385 - accuracy: 0.9734 - val_loss: 7.7867 - val_accuracy: 0.0744\n",
            "Epoch 42/120\n",
            "212/212 [==============================] - 16s 75ms/step - loss: 0.0396 - accuracy: 0.9753 - val_loss: 7.3192 - val_accuracy: 0.0763\n",
            "Epoch 43/120\n",
            "212/212 [==============================] - 16s 76ms/step - loss: 0.0379 - accuracy: 0.9742 - val_loss: 7.5884 - val_accuracy: 0.0770\n",
            "Epoch 44/120\n",
            "212/212 [==============================] - 17s 79ms/step - loss: 0.0385 - accuracy: 0.9750 - val_loss: 7.7008 - val_accuracy: 0.0732\n",
            "Epoch 45/120\n",
            "212/212 [==============================] - 16s 77ms/step - loss: 0.0392 - accuracy: 0.9736 - val_loss: 7.6692 - val_accuracy: 0.0763\n",
            "Epoch 46/120\n",
            "212/212 [==============================] - 17s 79ms/step - loss: 0.0368 - accuracy: 0.9739 - val_loss: 7.2390 - val_accuracy: 0.0763\n",
            "Epoch 47/120\n",
            "212/212 [==============================] - 16s 75ms/step - loss: 0.0382 - accuracy: 0.9731 - val_loss: 7.6738 - val_accuracy: 0.0757\n",
            "Epoch 48/120\n",
            "212/212 [==============================] - 16s 75ms/step - loss: 0.0403 - accuracy: 0.9726 - val_loss: 7.1168 - val_accuracy: 0.0713\n",
            "Epoch 49/120\n",
            "212/212 [==============================] - 16s 76ms/step - loss: 0.0434 - accuracy: 0.9745 - val_loss: 7.2437 - val_accuracy: 0.0801\n",
            "Epoch 50/120\n",
            "212/212 [==============================] - 17s 80ms/step - loss: 0.0483 - accuracy: 0.9738 - val_loss: 7.5515 - val_accuracy: 0.0814\n",
            "Epoch 51/120\n",
            "212/212 [==============================] - 16s 75ms/step - loss: 0.0469 - accuracy: 0.9732 - val_loss: 7.2929 - val_accuracy: 0.0801\n",
            "Epoch 52/120\n",
            "212/212 [==============================] - 16s 75ms/step - loss: 0.0445 - accuracy: 0.9756 - val_loss: 6.7334 - val_accuracy: 0.0732\n",
            "Epoch 53/120\n",
            "212/212 [==============================] - 16s 77ms/step - loss: 0.0415 - accuracy: 0.9735 - val_loss: 7.4123 - val_accuracy: 0.0839\n",
            "Epoch 54/120\n",
            "212/212 [==============================] - 17s 79ms/step - loss: 0.0465 - accuracy: 0.9744 - val_loss: 6.7764 - val_accuracy: 0.0801\n",
            "Epoch 55/120\n",
            "212/212 [==============================] - 16s 75ms/step - loss: 0.0475 - accuracy: 0.9750 - val_loss: 6.9878 - val_accuracy: 0.0763\n",
            "Epoch 56/120\n",
            "212/212 [==============================] - 16s 75ms/step - loss: 0.0487 - accuracy: 0.9735 - val_loss: 6.5647 - val_accuracy: 0.0719\n",
            "Epoch 57/120\n",
            "212/212 [==============================] - 16s 76ms/step - loss: 0.0594 - accuracy: 0.9707 - val_loss: 8.0331 - val_accuracy: 0.0492\n",
            "Epoch 58/120\n",
            "212/212 [==============================] - 17s 80ms/step - loss: 0.1406 - accuracy: 0.9522 - val_loss: 8.7449 - val_accuracy: 0.0562\n",
            "Epoch 59/120\n",
            "212/212 [==============================] - 16s 75ms/step - loss: 0.0852 - accuracy: 0.9667 - val_loss: 8.9074 - val_accuracy: 0.0662\n",
            "Epoch 60/120\n",
            "212/212 [==============================] - 16s 74ms/step - loss: 0.0506 - accuracy: 0.9711 - val_loss: 8.1486 - val_accuracy: 0.0625\n",
            "Epoch 61/120\n",
            "212/212 [==============================] - 16s 75ms/step - loss: 0.0417 - accuracy: 0.9745 - val_loss: 7.7718 - val_accuracy: 0.0625\n",
            "Epoch 62/120\n",
            "212/212 [==============================] - 17s 80ms/step - loss: 0.0381 - accuracy: 0.9728 - val_loss: 7.5203 - val_accuracy: 0.0612\n",
            "Epoch 63/120\n",
            "212/212 [==============================] - 16s 76ms/step - loss: 0.0345 - accuracy: 0.9728 - val_loss: 7.9521 - val_accuracy: 0.0637\n",
            "Epoch 64/120\n",
            "212/212 [==============================] - 16s 74ms/step - loss: 0.0330 - accuracy: 0.9739 - val_loss: 7.8468 - val_accuracy: 0.0662\n",
            "Epoch 65/120\n",
            "212/212 [==============================] - 16s 73ms/step - loss: 0.0347 - accuracy: 0.9729 - val_loss: 7.6897 - val_accuracy: 0.0625\n",
            "Epoch 66/120\n",
            "212/212 [==============================] - 17s 79ms/step - loss: 0.0359 - accuracy: 0.9763 - val_loss: 7.5557 - val_accuracy: 0.0650\n",
            "Epoch 67/120\n",
            "212/212 [==============================] - 16s 76ms/step - loss: 0.0338 - accuracy: 0.9776 - val_loss: 7.8908 - val_accuracy: 0.0650\n",
            "Epoch 68/120\n",
            "212/212 [==============================] - 17s 78ms/step - loss: 0.0323 - accuracy: 0.9756 - val_loss: 7.6648 - val_accuracy: 0.0650\n",
            "Epoch 69/120\n",
            "212/212 [==============================] - 16s 76ms/step - loss: 0.0320 - accuracy: 0.9766 - val_loss: 7.7437 - val_accuracy: 0.0637\n",
            "Epoch 70/120\n",
            "212/212 [==============================] - 16s 74ms/step - loss: 0.0317 - accuracy: 0.9776 - val_loss: 7.5872 - val_accuracy: 0.0662\n",
            "Epoch 71/120\n",
            "212/212 [==============================] - 16s 74ms/step - loss: 0.0326 - accuracy: 0.9745 - val_loss: 7.7639 - val_accuracy: 0.0675\n",
            "Epoch 72/120\n",
            "212/212 [==============================] - 17s 79ms/step - loss: 0.0327 - accuracy: 0.9781 - val_loss: 7.7354 - val_accuracy: 0.0713\n",
            "Epoch 73/120\n",
            "212/212 [==============================] - 16s 77ms/step - loss: 0.0329 - accuracy: 0.9750 - val_loss: 7.9277 - val_accuracy: 0.0707\n",
            "Epoch 74/120\n",
            "212/212 [==============================] - 16s 74ms/step - loss: 0.0324 - accuracy: 0.9754 - val_loss: 7.5321 - val_accuracy: 0.0694\n",
            "Epoch 75/120\n",
            "212/212 [==============================] - 16s 73ms/step - loss: 0.0340 - accuracy: 0.9756 - val_loss: 7.4741 - val_accuracy: 0.0656\n",
            "Epoch 76/120\n",
            "212/212 [==============================] - 17s 79ms/step - loss: 0.0338 - accuracy: 0.9753 - val_loss: 7.8273 - val_accuracy: 0.0650\n",
            "Epoch 77/120\n",
            "212/212 [==============================] - 17s 78ms/step - loss: 0.0378 - accuracy: 0.9744 - val_loss: 7.5409 - val_accuracy: 0.0656\n",
            "Epoch 78/120\n",
            "212/212 [==============================] - 16s 74ms/step - loss: 0.0490 - accuracy: 0.9747 - val_loss: 7.3400 - val_accuracy: 0.0694\n",
            "Epoch 79/120\n",
            "212/212 [==============================] - 16s 74ms/step - loss: 0.0474 - accuracy: 0.9722 - val_loss: 7.3175 - val_accuracy: 0.0738\n",
            "Epoch 80/120\n",
            "212/212 [==============================] - 16s 77ms/step - loss: 0.0443 - accuracy: 0.9734 - val_loss: 7.2537 - val_accuracy: 0.0833\n",
            "Epoch 81/120\n",
            "212/212 [==============================] - 17s 78ms/step - loss: 0.0383 - accuracy: 0.9742 - val_loss: 7.0437 - val_accuracy: 0.0700\n",
            "Epoch 82/120\n",
            "212/212 [==============================] - 16s 74ms/step - loss: 0.0371 - accuracy: 0.9763 - val_loss: 7.0796 - val_accuracy: 0.0757\n",
            "Epoch 83/120\n",
            "212/212 [==============================] - 16s 74ms/step - loss: 0.0362 - accuracy: 0.9751 - val_loss: 6.9791 - val_accuracy: 0.0776\n",
            "Epoch 84/120\n",
            "212/212 [==============================] - 16s 77ms/step - loss: 0.0365 - accuracy: 0.9747 - val_loss: 6.7860 - val_accuracy: 0.0763\n",
            "Epoch 85/120\n",
            "212/212 [==============================] - 17s 79ms/step - loss: 0.0355 - accuracy: 0.9753 - val_loss: 6.9320 - val_accuracy: 0.0826\n",
            "Epoch 86/120\n",
            "212/212 [==============================] - 17s 78ms/step - loss: 0.0368 - accuracy: 0.9745 - val_loss: 6.9488 - val_accuracy: 0.0770\n",
            "Epoch 87/120\n",
            "212/212 [==============================] - 17s 79ms/step - loss: 0.0371 - accuracy: 0.9748 - val_loss: 6.6515 - val_accuracy: 0.0763\n",
            "Epoch 88/120\n",
            "212/212 [==============================] - 16s 73ms/step - loss: 0.0388 - accuracy: 0.9753 - val_loss: 6.5675 - val_accuracy: 0.0707\n",
            "Epoch 89/120\n",
            "212/212 [==============================] - 16s 74ms/step - loss: 0.0387 - accuracy: 0.9745 - val_loss: 6.8547 - val_accuracy: 0.0770\n",
            "Epoch 90/120\n",
            "212/212 [==============================] - 16s 76ms/step - loss: 0.0440 - accuracy: 0.9736 - val_loss: 6.7285 - val_accuracy: 0.0789\n",
            "Epoch 91/120\n",
            "212/212 [==============================] - 17s 79ms/step - loss: 0.0379 - accuracy: 0.9726 - val_loss: 6.7259 - val_accuracy: 0.0751\n",
            "Epoch 92/120\n",
            "212/212 [==============================] - 16s 74ms/step - loss: 0.0352 - accuracy: 0.9747 - val_loss: 6.8358 - val_accuracy: 0.0814\n",
            "Epoch 93/120\n",
            "212/212 [==============================] - 16s 73ms/step - loss: 0.0370 - accuracy: 0.9754 - val_loss: 6.3553 - val_accuracy: 0.0757\n",
            "Epoch 94/120\n",
            "212/212 [==============================] - 16s 77ms/step - loss: 0.0386 - accuracy: 0.9736 - val_loss: 6.3758 - val_accuracy: 0.0808\n",
            "Epoch 95/120\n",
            "212/212 [==============================] - 17s 79ms/step - loss: 0.0402 - accuracy: 0.9742 - val_loss: 6.3587 - val_accuracy: 0.0826\n",
            "Epoch 96/120\n",
            "212/212 [==============================] - 15s 72ms/step - loss: 0.0378 - accuracy: 0.9734 - val_loss: 6.8821 - val_accuracy: 0.0826\n",
            "Epoch 97/120\n",
            "212/212 [==============================] - 15s 73ms/step - loss: 0.0353 - accuracy: 0.9763 - val_loss: 6.6758 - val_accuracy: 0.0877\n",
            "Epoch 98/120\n",
            "212/212 [==============================] - 16s 75ms/step - loss: 0.0333 - accuracy: 0.9742 - val_loss: 6.9370 - val_accuracy: 0.0763\n",
            "Epoch 99/120\n",
            "212/212 [==============================] - 16s 78ms/step - loss: 0.0337 - accuracy: 0.9750 - val_loss: 7.0560 - val_accuracy: 0.0845\n",
            "Epoch 100/120\n",
            "212/212 [==============================] - 15s 72ms/step - loss: 0.0334 - accuracy: 0.9745 - val_loss: 6.2842 - val_accuracy: 0.0744\n",
            "Epoch 101/120\n",
            "212/212 [==============================] - 15s 73ms/step - loss: 0.0336 - accuracy: 0.9748 - val_loss: 7.1108 - val_accuracy: 0.0871\n",
            "Epoch 102/120\n",
            "212/212 [==============================] - 16s 74ms/step - loss: 0.0346 - accuracy: 0.9759 - val_loss: 7.4772 - val_accuracy: 0.0732\n",
            "Epoch 103/120\n",
            "212/212 [==============================] - 16s 78ms/step - loss: 0.0422 - accuracy: 0.9731 - val_loss: 6.5315 - val_accuracy: 0.0795\n",
            "Epoch 104/120\n",
            "212/212 [==============================] - 16s 73ms/step - loss: 0.0419 - accuracy: 0.9747 - val_loss: 6.7779 - val_accuracy: 0.0726\n",
            "Epoch 105/120\n",
            "212/212 [==============================] - 16s 74ms/step - loss: 0.0413 - accuracy: 0.9739 - val_loss: 6.6890 - val_accuracy: 0.0713\n",
            "Epoch 106/120\n",
            "212/212 [==============================] - 16s 73ms/step - loss: 0.0358 - accuracy: 0.9719 - val_loss: 6.9752 - val_accuracy: 0.0763\n",
            "Epoch 107/120\n",
            "212/212 [==============================] - 16s 78ms/step - loss: 0.0337 - accuracy: 0.9728 - val_loss: 6.6079 - val_accuracy: 0.0713\n",
            "Epoch 108/120\n",
            "212/212 [==============================] - 16s 75ms/step - loss: 0.0338 - accuracy: 0.9736 - val_loss: 6.5614 - val_accuracy: 0.0744\n",
            "Epoch 109/120\n",
            "212/212 [==============================] - 16s 78ms/step - loss: 0.0329 - accuracy: 0.9751 - val_loss: 6.1571 - val_accuracy: 0.0732\n",
            "Epoch 110/120\n",
            "212/212 [==============================] - 16s 75ms/step - loss: 0.0338 - accuracy: 0.9756 - val_loss: 6.7473 - val_accuracy: 0.0770\n",
            "Epoch 111/120\n",
            "212/212 [==============================] - 15s 73ms/step - loss: 0.0333 - accuracy: 0.9762 - val_loss: 6.9054 - val_accuracy: 0.0757\n",
            "Epoch 112/120\n",
            "212/212 [==============================] - 16s 73ms/step - loss: 0.0351 - accuracy: 0.9763 - val_loss: 6.6076 - val_accuracy: 0.0650\n",
            "Epoch 113/120\n",
            "212/212 [==============================] - 16s 78ms/step - loss: 0.0357 - accuracy: 0.9750 - val_loss: 7.6812 - val_accuracy: 0.0757\n",
            "Epoch 114/120\n",
            "212/212 [==============================] - 16s 76ms/step - loss: 0.0364 - accuracy: 0.9744 - val_loss: 7.4125 - val_accuracy: 0.0681\n",
            "Epoch 115/120\n",
            "212/212 [==============================] - 16s 73ms/step - loss: 0.0342 - accuracy: 0.9760 - val_loss: 6.7036 - val_accuracy: 0.0719\n",
            "Epoch 116/120\n",
            "212/212 [==============================] - 16s 73ms/step - loss: 0.0319 - accuracy: 0.9759 - val_loss: 7.3140 - val_accuracy: 0.0732\n",
            "Epoch 117/120\n",
            "212/212 [==============================] - 16s 77ms/step - loss: 0.0324 - accuracy: 0.9771 - val_loss: 7.2209 - val_accuracy: 0.0713\n",
            "Epoch 118/120\n",
            "212/212 [==============================] - 16s 76ms/step - loss: 0.0315 - accuracy: 0.9776 - val_loss: 6.8332 - val_accuracy: 0.0757\n",
            "Epoch 119/120\n",
            "212/212 [==============================] - 15s 73ms/step - loss: 0.0305 - accuracy: 0.9754 - val_loss: 6.7741 - val_accuracy: 0.0751\n",
            "Epoch 120/120\n",
            "212/212 [==============================] - 16s 73ms/step - loss: 0.0311 - accuracy: 0.9781 - val_loss: 7.5954 - val_accuracy: 0.0688\n",
            "Best epoch: 25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_RmaGone6Ct"
      },
      "source": [
        "*Experiment Notes: My model is performing well on the training data and non-optimal * "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT6DN-u4UbrQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aa9fQrvVOuh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo68UhQkXC77"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lm4uM98ummZr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PSyxtC-moEB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}