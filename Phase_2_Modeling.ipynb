{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Phase 2 Modeling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5PNemoygICJ"
      },
      "source": [
        "#Phase 2: Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_1wVH_KPCpd"
      },
      "source": [
        "#from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import sklearn as skl"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgvwUgWeo5z9"
      },
      "source": [
        "**Train, Test, Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0P9_pKUQR4p"
      },
      "source": [
        "#split validation set by 20%\n",
        "train_gen = ImageDataGenerator(rescale = 1./255, validation_split=0.20)\n",
        "test_gen = ImageDataGenerator(rescale = 1./255)\n",
        "#Image generator helps creating image aumentation to increase the amount of data we have\n",
        "#Will implement various rotations and flips to the images to distort"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DKUEBLPQXO4"
      },
      "source": [
        "def get_train_set(train_gen, input_size):\n",
        "  train_set = train_gen.flow_from_directory(\"/content/drive/MyDrive/DS 2 dataset/train\",\n",
        "                                         class_mode='categorical',\n",
        "                                         target_size= input_size,\n",
        "                                         color_mode = 'grayscale',\n",
        "                                         batch_size= 32, \n",
        "                                         shuffle = True, \n",
        "                                         subset ='training')\n",
        "  return train_set"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBzfnnGHk4ry"
      },
      "source": [
        "def get_validation_set(train_gen, input_size):\n",
        "  validation_set = train_gen.flow_from_directory(\"/content/drive/MyDrive/DS 2 dataset/train\",\n",
        "                                          target_size= input_size,\n",
        "                                          color_mode = 'grayscale',\n",
        "                                          class_mode='categorical',\n",
        "                                          batch_size= 32, \n",
        "                                          shuffle = True, \n",
        "                                          subset ='validation')\n",
        "  return validation_set"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twkedjBjoOrI"
      },
      "source": [
        "def get_test_set(test_gen, input_size):\n",
        "  test_set = test_gen.flow_from_directory(\"/content/drive/MyDrive/DS 2 dataset/test\",\n",
        "                                         target_size=input_size, \n",
        "                                         color_mode = 'grayscale',\n",
        "                                         class_mode='categorical',\n",
        "                                         batch_size= 1,\n",
        "                                         shuffle = True)\n",
        "  return test_set"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYQyxqAFo0cx"
      },
      "source": [
        "#Modeling & Hyper-parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne4oTBQblZKQ",
        "outputId": "88b16dee-c060-4575-a6b0-14483c50b223"
      },
      "source": [
        "!pip install -q -U keras-tuner"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█████▏                          | 10kB 23.9MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 40kB 12.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 61kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 4.9MB/s \n",
            "\u001b[?25h  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m77SM3xwKLiC"
      },
      "source": [
        "from keras.applications import mobilenet_v2 # least parameters (3 mil)\n",
        "from keras.applications import ResNet101 # (25 mil)\n",
        "from keras.applications import xception #most parameters (44 mil)\n",
        "import kerastuner as kt\n",
        "from kerastuner.tuners import RandomSearch"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqtjkvibKaHU"
      },
      "source": [
        "def build_mobileNet(hp):\n",
        "  model = mobilenet_v2.MobileNetV2(input_shape=(224,224,1),\n",
        "      weights = None,\n",
        "      classes = 196\n",
        "  )\n",
        "  \n",
        "  model.compile(optimizer= tf.keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2])),\n",
        "                loss = 'categorical_crossentropy',\n",
        "                metrics = 'accuracy')\n",
        "  return model "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGl4ayCxkqpF"
      },
      "source": [
        "def build_resNet(hp):\n",
        "  model = ResNet101(weights = None, classes = 196)\n",
        "\n",
        "  model.compile(optimizer= tf.keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2])),\n",
        "                loss = 'categorical_crossentropy',\n",
        "                metrics = 'accuracy')\n",
        "    \n",
        "  return model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIPh_cxsQ2Y_"
      },
      "source": [
        "tuner_1 = RandomSearch(hypermodel=build_mobileNet, objective='val_accuracy', max_trials= 1, seed = 25)\n",
        "tuner_2 = RandomSearch(hypermodel=build_resNet,objective='val_accuracy', max_trials= 1, seed = 25)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhD-vwo4iF56",
        "outputId": "6ac630ed-238e-457e-feba-c61bbdd232e4"
      },
      "source": [
        "tuner_1.search_space_summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Search space summary\n",
            "Default search space size: 1\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01], 'ordered': True}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T34XMt7EFFgE",
        "outputId": "8e5845d9-0ce3-4092-d7e3-c44501f9ac62"
      },
      "source": [
        "tuner_2.search_space_summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Search space summary\n",
            "Default search space size: 1\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01], 'ordered': True}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYDg6gvvjIqR",
        "outputId": "7362fd5e-d822-4a97-d2d9-d4f3e51dec6c"
      },
      "source": [
        "tuner_1.search(get_train_set(train_gen=train_gen, input_size = (224,224)), epochs = 50, validation_data = get_validation_set(train_gen=train_gen, input_size= (224,224)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6755 images belonging to 196 classes.\n",
            "Found 1585 images belonging to 196 classes.\n",
            "\n",
            "Search: Running Trial #1\n",
            "\n",
            "Hyperparameter    |Value             |Best Value So Far \n",
            "learning_rate     |0.01              |?                 \n",
            "\n",
            "Epoch 1/50\n",
            "212/212 [==============================] - 2417s 11s/step - loss: 6.2820 - accuracy: 0.0065 - val_loss: 5.2678 - val_accuracy: 0.0107\n",
            "Epoch 2/50\n",
            "212/212 [==============================] - 47s 221ms/step - loss: 5.2598 - accuracy: 0.0127 - val_loss: 5.2876 - val_accuracy: 0.0107\n",
            "Epoch 3/50\n",
            "212/212 [==============================] - 46s 216ms/step - loss: 5.2393 - accuracy: 0.0139 - val_loss: 5.2726 - val_accuracy: 0.0107\n",
            "Epoch 4/50\n",
            "212/212 [==============================] - 46s 217ms/step - loss: 5.2195 - accuracy: 0.0150 - val_loss: 5.2756 - val_accuracy: 0.0107\n",
            "Epoch 5/50\n",
            "212/212 [==============================] - 46s 216ms/step - loss: 5.1841 - accuracy: 0.0158 - val_loss: 5.2847 - val_accuracy: 0.0095\n",
            "Epoch 6/50\n",
            "212/212 [==============================] - 46s 217ms/step - loss: 5.1569 - accuracy: 0.0141 - val_loss: 5.2987 - val_accuracy: 0.0095\n",
            "Epoch 7/50\n",
            "212/212 [==============================] - 47s 220ms/step - loss: 5.1513 - accuracy: 0.0158 - val_loss: 5.2968 - val_accuracy: 0.0095\n",
            "Epoch 8/50\n",
            "212/212 [==============================] - 46s 218ms/step - loss: 5.1235 - accuracy: 0.0166 - val_loss: 13.0656 - val_accuracy: 0.0050\n",
            "Epoch 9/50\n",
            "212/212 [==============================] - 46s 218ms/step - loss: 5.1061 - accuracy: 0.0178 - val_loss: 18.0221 - val_accuracy: 0.0050\n",
            "Epoch 10/50\n",
            "212/212 [==============================] - 46s 218ms/step - loss: 5.0687 - accuracy: 0.0219 - val_loss: 18.7392 - val_accuracy: 0.0050\n",
            "Epoch 11/50\n",
            "212/212 [==============================] - 46s 218ms/step - loss: 5.0342 - accuracy: 0.0208 - val_loss: 15.9606 - val_accuracy: 0.0032\n",
            "Epoch 12/50\n",
            "212/212 [==============================] - 46s 217ms/step - loss: 4.9912 - accuracy: 0.0209 - val_loss: 17.3868 - val_accuracy: 0.0050\n",
            "Epoch 13/50\n",
            "212/212 [==============================] - 46s 215ms/step - loss: 4.8948 - accuracy: 0.0221 - val_loss: 13.6594 - val_accuracy: 0.0082\n",
            "Epoch 14/50\n",
            "212/212 [==============================] - 47s 220ms/step - loss: 4.7678 - accuracy: 0.0242 - val_loss: 8.6550 - val_accuracy: 0.0095\n",
            "Epoch 15/50\n",
            "212/212 [==============================] - 47s 219ms/step - loss: 4.6357 - accuracy: 0.0239 - val_loss: 12.3075 - val_accuracy: 0.0063\n",
            "Epoch 16/50\n",
            "212/212 [==============================] - 46s 217ms/step - loss: 4.5509 - accuracy: 0.0287 - val_loss: 13.9596 - val_accuracy: 0.0038\n",
            "Epoch 17/50\n",
            "212/212 [==============================] - 46s 216ms/step - loss: 4.4573 - accuracy: 0.0370 - val_loss: 22.1316 - val_accuracy: 0.0019\n",
            "Epoch 18/50\n",
            "212/212 [==============================] - 46s 218ms/step - loss: 4.4149 - accuracy: 0.0464 - val_loss: 15.8649 - val_accuracy: 0.0050\n",
            "Epoch 19/50\n",
            "212/212 [==============================] - 46s 217ms/step - loss: 4.2247 - accuracy: 0.0495 - val_loss: 16.9519 - val_accuracy: 0.0057\n",
            "Epoch 20/50\n",
            "212/212 [==============================] - 46s 217ms/step - loss: 4.1382 - accuracy: 0.0689 - val_loss: 20.4433 - val_accuracy: 0.0095\n",
            "Epoch 21/50\n",
            "212/212 [==============================] - 46s 218ms/step - loss: 4.1036 - accuracy: 0.0656 - val_loss: 26.0011 - val_accuracy: 0.0114\n",
            "Epoch 22/50\n",
            "212/212 [==============================] - 46s 216ms/step - loss: 3.9131 - accuracy: 0.0824 - val_loss: 28.8610 - val_accuracy: 0.0025\n",
            "Epoch 23/50\n",
            "212/212 [==============================] - 46s 216ms/step - loss: 3.8472 - accuracy: 0.0905 - val_loss: 42.5972 - val_accuracy: 0.0082\n",
            "Epoch 24/50\n",
            "212/212 [==============================] - 46s 218ms/step - loss: 3.6555 - accuracy: 0.1145 - val_loss: 35.2378 - val_accuracy: 6.3091e-04\n",
            "Epoch 25/50\n",
            "212/212 [==============================] - 46s 217ms/step - loss: 3.5576 - accuracy: 0.1325 - val_loss: 30.6251 - val_accuracy: 0.0076\n",
            "Epoch 26/50\n",
            "212/212 [==============================] - 46s 217ms/step - loss: 3.4500 - accuracy: 0.1556 - val_loss: 42.3412 - val_accuracy: 0.0095\n",
            "Epoch 27/50\n",
            "212/212 [==============================] - 46s 218ms/step - loss: 3.3250 - accuracy: 0.1712 - val_loss: 30.6748 - val_accuracy: 0.0057\n",
            "Epoch 28/50\n",
            "212/212 [==============================] - 46s 216ms/step - loss: 3.1423 - accuracy: 0.2034 - val_loss: 37.8112 - val_accuracy: 0.0114\n",
            "Epoch 29/50\n",
            "212/212 [==============================] - 46s 216ms/step - loss: 2.9636 - accuracy: 0.2282 - val_loss: 30.0938 - val_accuracy: 0.0120\n",
            "Epoch 30/50\n",
            "212/212 [==============================] - 46s 217ms/step - loss: 2.8476 - accuracy: 0.2505 - val_loss: 36.3866 - val_accuracy: 0.0095\n",
            "Epoch 31/50\n",
            "212/212 [==============================] - 46s 218ms/step - loss: 2.7175 - accuracy: 0.2712 - val_loss: 33.7183 - val_accuracy: 0.0114\n",
            "Epoch 32/50\n",
            "209/212 [============================>.] - ETA: 0s - loss: 2.5931 - accuracy: 0.3008"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRRJd1UClXT2"
      },
      "source": [
        "tuner_2.search(get_train_set(train_gen=train_gen, input_size = (224,224,3)), epochs = 50, validation_data = get_validation_set(train_gen=train_gen, input_size= (224,224,3)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb7xu_Qjf4_t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}